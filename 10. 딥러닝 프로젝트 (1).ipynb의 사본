{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1YOeFTiCi8GBLmG8MWzksGdb4IfT85R5X","timestamp":1687418628886}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 2. Boston 주택 가격 예측 모델\n","\n","\n","## 데이터 로드 및 전처리"],"metadata":{"id":"CNHDxVVFRP7y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wt2_eOVRMVc"},"outputs":[],"source":["from tensorflow.keras import models, layers\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# keras.datasets 안에 boston_housing 데이터셋을 로드합니다.\n","from keras.datasets import boston_housing\n","\n","(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n","\n","# 데이터셋의 크기를 확인합니다.\n","print(len(train_data))\n","print(len(test_data))"],"metadata":{"id":"X7oaEXMmRhLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 1-1: 데이터셋의 전처리를 위해 표준화 작업을 수행합니다.\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# 먼저 입력 데이터의 각 특성의 평균을 뺍니다.\n","\n","mean = train_data.mean(axis=0)\n","train_data -= mean\n","\n","\n","# 평균을 뺀 입력 데이터에서 표준편차를 나눕니다.\n","feature_stds = np.std(train_data, axis=0)\n","train_data /= feature_stds\n","\n","\n","# 데이터 특성의 중앙이 0에 가깝게 만들고, 표준편차가 1이 되게 만듭니다.\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(train_data)\n","train_data_scaled = scaler.transform(train_data)\n","test_data_scaled = scaler.transform(test_data)\n","\n","\n","# 테스트 데이터셋도 마찬가지로 평균을 빼고, 표준편차로 나눕니다.\n","test_data -= mean\n","test_data /= feature_stds\n"],"metadata":{"id":"MqTEDhcORmEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"x62uGTkq_Zt1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 구성 및 컴파일"],"metadata":{"id":"dev7q7sWWc9l"}},{"cell_type":"code","source":["# 문제 1-2: 주택 가격 예측을 위한 딥러닝 모델 구성 및 컴파일합니다.\n","# input_shape은 (train_data.shape[1], )으로 구성합니다.\n","# 회귀(예측)을 위한 모델이므로 loss를 mse, metrics를 mae로 사용합니다.\n","\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(1))\n","\n","model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"],"metadata":{"id":"6HbiugSTVcPk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 학습"],"metadata":{"id":"7fYj0Ud8Wf0C"}},{"cell_type":"code","source":["# 문제 1-3: 예측을 위한 딥러닝 모델을 학습합니다.\n","\n","history = model.fit(train_data, train_labels, epochs=100, batch_size=1, verbose=1)"],"metadata":{"id":"5S_ZpBxQVjUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습 히스토리에서 loss, val_loss, mae, val_mae를 차트로 보여줍니다.\n","import matplotlib.pyplot as plt\n","\n","plt.style.use('seaborn-white')\n","\n","history_dict = history.history\n","\n","loss = history_dict['loss']\n","val_loss = history_dict.get('val_loss', None)  # val_loss 키가 없는 경우 None을 반환\n","\n","epochs = range(1, len(loss) + 1)\n","fig = plt.figure(figsize=(12, 5))\n","\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax1.plot(epochs, loss, 'b-', label='train_loss')\n","if val_loss is not None:\n","    ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n","ax1.set_title('Train and Validation Loss')\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Loss')\n","ax1.grid()\n","ax1.legend()\n","\n","mae = history_dict['mae']\n","val_mae = history_dict.get('val_mae', None)  # val_mae 키가 없는 경우 None을 반환\n","\n","ax2 = fig.add_subplot(1, 2, 2)\n","ax2.plot(epochs, mae, 'b-', label='train_mae')\n","if val_mae is not None:\n","    ax2.plot(epochs, val_mae, 'r-', label='val_mae')\n","ax2.set_title('Train and Validation MAE')\n","ax2.set_xlabel('Epochs')\n","ax2.set_ylabel('MAE')\n","ax2.grid()\n","ax2.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"IyZnp1MQVr_K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 평가 및 예측"],"metadata":{"id":"LytsIpXAWkuP"}},{"cell_type":"code","source":["# 문제 1-4: 테스트 데이터셋을 이용해 모델을 평가합니다.\n","\n","test_loss, test_mae = model.evaluate(test_data, test_labels)\n","\n","print(\"Test Loss:\", test_loss)\n","print(\"Test MAE:\", test_mae)"],"metadata":{"id":"8j7Hr2L0WBhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Reuters 딥러닝 모델\n","\n"," ## 데이터 로드 및 전처리\n"],"metadata":{"id":"XCKKSl7EWTms"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras import models, layers\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import utils\n","from keras.datasets import reuters"],"metadata":{"id":"-7qVskVaWs-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 2-1: reuters 데이터셋을 로드하고, 훈련 데이터셋에서 25%를 검증 데이터셋으로 분리합니다.\n","# [[YOUR CODE]]\n","# Reuters 데이터셋 로드\n","(train_data, train_labels), (test_data, test_labels) = reuters.load_data()\n","\n","# 데이터 전처리\n","num_classes = max(train_labels) + 1\n","\n","# 훈련 데이터셋과 검증 데이터셋으로 분리 (25%를 검증 데이터셋으로 설정)\n","train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=42)\n","\n","\n","# 훈련, 검증, 테스트 데이터와 레이블 종류가 몇 개인지 출력합니다.\n","print(len(train_data))\n","print(len(val_data))\n","print(len(test_data))\n","print(len(set(train_labels)))"],"metadata":{"id":"5dEiu7CRWv48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 2-2: 텍스트 데이터의 전처리를 위해서 각 데이터셋마다 원-핫 인코딩을 수행합니다.\n","from tensorflow.keras import utils\n","\n","def one_hot_encoding(data, dim=10000):\n","    results = np.zeros((len(data), dim))\n","    for i, sequence in enumerate(data):\n","        for index in sequence:\n","            if index < dim:\n","                results[i, index] = 1.\n","    return results\n","\n","# 원-핫 인코딩 적용\n","x_train = one_hot_encoding(train_data)\n","x_val = one_hot_encoding(val_data)\n","x_test = one_hot_encoding(test_data)\n","\n","# 레이블 데이터들은 범주형 형태로 to_categorical() 함수를 사용해 변환합니다.\n","# [[YOUR CODE]]\n","\n","\n","# 레이블 데이터들을 범주형 형태로 변환\n","num_classes = max(train_labels) + 1\n","y_train = utils.to_categorical(train_labels, num_classes)\n","y_val = utils.to_categorical(val_labels, num_classes)\n","y_test = utils.to_categorical(test_labels, num_classes)\n"],"metadata":{"id":"s1K5_jXxWyEF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 구성 및 컴파일"],"metadata":{"id":"2aAXe0AEWsn8"}},{"cell_type":"code","source":["# 문제 2-3: 빠른 학습과 과대적합을 방지하기 위해 BatchNormalization과 Dropout을 적용한 딥러닝 모델을 구성합니다.\n","# [[YOUR CODE]]\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(46, activation='softmax'))\n","\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"7Q6kcwrbW4m9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"Vylh0tF6W9Wj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 학습"],"metadata":{"id":"UCCxz2ooXAHI"}},{"cell_type":"code","source":["# 문제 2-4: ModelCheckpoint와 EarlyStopping 콜백 함수를 적용하여 모델 학습을 진행합니다.\n","# [[YOUR CODE]]\n","# ModelCheckpoint 콜백 생성\n","checkpoint = callbacks.ModelCheckpoint('model_checkpoint.h5', monitor='val_loss', save_best_only=True)\n","\n","# EarlyStopping 콜백 생성\n","early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","\n","# 모델 훈련 시 콜백 지정\n","history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[checkpoint, early_stopping])"],"metadata":{"id":"I8ZilqD0XBsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 히스토리의 `loss`, `val_loss`, `accuracy`, `val_accuracy`를 차트로 시각화합니다.\n","plt.style.use('seaborn-white')\n","\n","history_dict = history.history\n","\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(loss) + 1)\n","fig = plt.figure(figsize=(12, 5))\n","\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax1.plot(epochs, loss, 'b-', label='train_loss')\n","ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n","ax1.set_title('Train and Validation Loss')\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Loss')\n","ax1.grid()\n","ax1.legend()\n","\n","accuracy = history_dict['accuracy']\n","val_accuracy = history_dict['val_accuracy']\n","\n","ax2 = fig.add_subplot(1, 2, 2)\n","ax2.plot(epochs, accuracy, 'b-', label='train_accuracy')\n","ax2.plot(epochs, val_accuracy, 'r-', label='val_accuracy')\n","ax2.set_title('Train and Validation Accuracy')\n","ax2.set_xlabel('Epochs')\n","ax2.set_ylabel('Accuracy')\n","ax2.grid()\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"svq6yVgpXEvC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 평가 및 예측\n"],"metadata":{"id":"sfdcbEGzXTpc"}},{"cell_type":"code","source":["# 문제 2-5: 테스트 데이터셋을 이용해 모델을 평가합니다.\n","# [[YOUR CODE]]\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"id":"FrA0oZesXPoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. CIFAR10 딥러닝 모델\n"," ## 데이터 로드 및 전처리"],"metadata":{"id":"zkbCJs1UXgws"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.datasets import cifar10"],"metadata":{"id":"hmYR4eOpXo9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 3-1: cifar10 데이터셋을 로드하고, 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리합니다.\n","\n","# 데이터셋을 로드\n","(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n","\n","# 20%를 검증 데이터셋으로 분리\n","x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n","\n","\n","# 훈련, 검증, 테스트 데이터와 레이블 종류가 몇개인지 출력합니다.\n","print(\"전체 학습 데이터: {} 레이블: {}\".format(x_train_full.shape, y_train_full.shape))\n","print(\"학습 데이터: {} 레이블: {}\".format(x_train.shape, y_train.shape))\n","print(\"검증 데이터: {} 레이블: {}\".format(x_val.shape, y_val.shape))\n","print(\"테스트 데이터: {} 레이블: {}\".format(x_test.shape, y_test.shape))"],"metadata":{"id":"xc9Au40BXsm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cifar10의 분류에 해당하는 'airplane', 'automobile', 'bird', 'cat', 'deer',\n","# 'dog', 'frog', 'horse', 'ship', 'truck'를 class_name으로 정의합니다.\n","class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck']"],"metadata":{"id":"46ONbfl9XwSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터의 0번째인 x_train[0]를 이미지로 시각화합니다.\n","plt.style.use('seaborn-white')\n","\n","plt.figure()\n","plt.imshow(x_train[0])\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"2VFhksFtXyuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련, 검증, 테스트 데이터의 형태(shape)을 출력합니다.\n","print(x_train.shape)\n","print(x_val.shape)\n","print(x_test.shape)"],"metadata":{"id":"1LCzNL-UaL13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 3-2: 훈련, 검증, 테스트 데이터의 형태(shape)을 32 * 32 * 3 = 3072로 변형합니다.\n","import numpy as np\n","\n","x_train_reshaped = np.reshape(x_train, (x_train.shape[0], 32 * 32 * 3))\n","x_val_reshaped = np.reshape(x_val, (x_val.shape[0], 32 * 32 * 3))\n","x_test_reshaped = np.reshape(x_test, (x_test.shape[0], 32 * 32 * 3))\n","\n","print(x_train.shape)\n","print(x_val.shape)\n","print(x_test.shape)"],"metadata":{"id":"rrFUyrzyX6Jy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련, 검증, 테스트 데이터를 255로 나누어 0~1 사이의 값으로 변환합니다.\n","x_train = x_train / 255.\n","x_val = x_val / 255.\n","x_test = x_test / 255."],"metadata":{"id":"urYiiuXQYKBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 구성 및 컴파일"],"metadata":{"id":"NnoUsQrCYQFZ"}},{"cell_type":"code","source":["# 문제 3-3: BatchNormalization과 Dropout을 적용하여 빠른 학습과 과대적합을 방지하고,\n","# 10개의 이미지를 분류하는 딥러닝 모델을 구성합니다.\n","\n","from tensorflow.keras.layers import BatchNormalization, Dropout\n","\n","# 이미지를 분류하는 딥러닝 모델을 구성\n","model = models.Sequential()\n","model.add(layers.Dense(256, activation='relu', input_shape=(3072,)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# 컴파일 모델\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"zhMeLoMGYOM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"gzGso6fWYXyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["utils.plot_model(model, show_shapes=True)"],"metadata":{"id":"oKP_diQaYaCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 학습"],"metadata":{"id":"kmteKDOtYf45"}},{"cell_type":"code","source":["# 문제 3-4: ModelCheckpoint와 EarlyStopping 콜백 함수를 적용하여 모델 학습을 진행합니다.\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# Create the model\n","model = models.Sequential()\n","model.add(layers.Flatten(input_shape=(32, 32, 3)))\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define the callbacks\n","checkpoint = ModelCheckpoint(filepath='checkpoint-{epoch:02d}-{val_loss:.5f}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, mode='auto')\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, restore_best_weights=True)\n","\n","# Train the model with callbacks\n","history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=128, callbacks=[checkpoint, early_stopping])\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_accuracy)"],"metadata":{"id":"1v0lJVPbgp-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문제 3-5: 학습 히스토리의 `loss`, `val_loss`, `accuracy`, `val_accuracy`를 차트로 시각화합니다.\n","\n","import matplotlib.pyplot as plt\n","\n","# Plot the training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot the training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"uJT2-uB7jtZZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 평가 및 예측"],"metadata":{"id":"MJ3grZoOjoDy"}},{"cell_type":"code","source":["# 테스트 데이터셋을 이용해 모델을 평가합니다.\n","model.evaluate(x_test, y_test)"],"metadata":{"id":"yMo8tTyJjoga"},"execution_count":null,"outputs":[]}]}